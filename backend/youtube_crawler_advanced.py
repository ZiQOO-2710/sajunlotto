#!/usr/bin/env python3
"""
ê³ ê¸‰ YouTube ì‚¬ì£¼ ì½˜í…ì¸  í¬ë¡¤ëŸ¬
ëŒ€ì¤‘ì ìœ¼ë¡œ ê²€ì¦ëœ ì „ë¬¸ê°€ ì½˜í…ì¸ ë¥¼ ìë™ìœ¼ë¡œ ìˆ˜ì§‘í•˜ê³  í•™ìŠµ
"""

import asyncio
import os
import re
import json
import sqlite3
from typing import List, Dict, Optional, Tuple
from datetime import datetime
from googleapiclient.discovery import build
from youtube_transcript_api import YouTubeTranscriptApi
import yt_dlp

class AdvancedSajuCrawler:
    """ì‚¬ì£¼ ì „ë¬¸ YouTube ì½˜í…ì¸  í¬ë¡¤ëŸ¬"""
    
    def __init__(self, api_key: str = None):
        self.api_key = api_key or os.getenv('YOUTUBE_API_KEY')
        self.youtube = None
        if self.api_key:
            self.youtube = build('youtube', 'v3', developerKey=self.api_key)
        
        # ê²€ìƒ‰ í‚¤ì›Œë“œ ì •ì˜
        self.search_keywords = [
            "ì‚¬ì£¼í’€ì´",
            "ëª…ë¦¬í•™ ê°•ì˜", 
            "ì‚¬ì£¼ ìƒë‹´",
            "ì¼ê°„ë³„ ìš´ì„¸",
            "ì‹ ë…„ìš´ì„¸",
            "ê°‘ëª© ì¼ì£¼",
            "ì„ëª© ì¼ì£¼",
            "ë³‘í™” ì¼ì£¼",
            "ì •í™” ì¼ì£¼",
            "ë¬´í†  ì¼ì£¼",
            "ê¸°í†  ì¼ì£¼",
            "ê²½ê¸ˆ ì¼ì£¼",
            "ì‹ ê¸ˆ ì¼ì£¼",
            "ì„ìˆ˜ ì¼ì£¼",
            "ê³„ìˆ˜ ì¼ì£¼",
            "ì‚¬ì£¼íŒ”ì í•´ì„",
            "ì‹­ì‹  í•´ì„",
            "ëŒ€ìš´ í’€ì´",
            "ê¶í•© ì‚¬ì£¼"
        ]
        
        # í•„í„°ë§ ê¸°ì¤€
        self.min_view_count = 100000  # 10ë§Œ íšŒ ì´ìƒ
        self.min_subscriber_count = 10000  # 1ë§Œ ëª… ì´ìƒ
        
        # ì œê±°í•  íŒ¨í„´ë“¤
        self.removal_patterns = [
            r"ì•ˆë…•í•˜ì„¸ìš”.*?ì…ë‹ˆë‹¤",
            r"êµ¬ë….*?ì¢‹ì•„ìš”.*?ë¶€íƒ",
            r"ì•Œë¦¼.*?ì„¤ì •",
            r"ê´‘ê³ .*?ë¬¸ì˜",
            r"í›„ì›.*?ë§í¬",
            r"ìŒ+\.\.\.",
            r"ì–´+\.\.\.",
            r"ê·¸+\.\.\.",
            r"\n{3,}",  # ê³¼ë„í•œ ì¤„ë°”ê¿ˆ
        ]
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
        self._init_database()
    
    def _init_database(self):
        """í¬ë¡¤ë§ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
        conn = sqlite3.connect('saju_youtube_data.db')
        cursor = conn.cursor()
        
        # í¬ë¡¤ë§ëœ ì˜ìƒ ì •ë³´
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS crawled_videos (
                video_id TEXT PRIMARY KEY,
                title TEXT,
                channel_name TEXT,
                channel_id TEXT,
                view_count INTEGER,
                subscriber_count INTEGER,
                duration INTEGER,
                upload_date TEXT,
                description TEXT,
                crawled_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
        # ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ë°ì´í„°
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS extracted_texts (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                video_id TEXT,
                source_type TEXT,  -- 'subtitle' or 'stt'
                raw_text TEXT,
                cleaned_text TEXT,
                extraction_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (video_id) REFERENCES crawled_videos(video_id)
            )
        """)
        
        # êµ¬ì¡°í™”ëœ í•™ìŠµ ë°ì´í„°
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS structured_learning_data (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                video_id TEXT,
                question TEXT,
                answer TEXT,
                saju_info TEXT,  -- JSON
                interpretation TEXT,
                confidence_score REAL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (video_id) REFERENCES crawled_videos(video_id)
            )
        """)
        
        conn.commit()
        conn.close()
    
    async def search_videos(self, keyword: str, max_results: int = 50) -> List[Dict]:
        """YouTube APIë¥¼ ì‚¬ìš©í•œ ì˜ìƒ ê²€ìƒ‰"""
        if not self.youtube:
            print("âŒ YouTube API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return []
        
        try:
            search_response = self.youtube.search().list(
                q=keyword,
                part='id,snippet',
                type='video',
                maxResults=max_results,
                order='viewCount',
                regionCode='KR',
                relevanceLanguage='ko'
            ).execute()
            
            videos = []
            for item in search_response.get('items', []):
                video_id = item['id']['videoId']
                
                # ì˜ìƒ ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                video_details = self.youtube.videos().list(
                    part='statistics,contentDetails',
                    id=video_id
                ).execute()
                
                if video_details['items']:
                    stats = video_details['items'][0]['statistics']
                    view_count = int(stats.get('viewCount', 0))
                    
                    # ì¡°íšŒìˆ˜ í•„í„°ë§
                    if view_count >= self.min_view_count:
                        # ì±„ë„ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                        channel_id = item['snippet']['channelId']
                        channel_info = self.youtube.channels().list(
                            part='statistics',
                            id=channel_id
                        ).execute()
                        
                        if channel_info['items']:
                            subscriber_count = int(
                                channel_info['items'][0]['statistics'].get('subscriberCount', 0)
                            )
                            
                            # êµ¬ë…ì ìˆ˜ í•„í„°ë§
                            if subscriber_count >= self.min_subscriber_count:
                                videos.append({
                                    'video_id': video_id,
                                    'title': item['snippet']['title'],
                                    'channel_name': item['snippet']['channelTitle'],
                                    'channel_id': channel_id,
                                    'view_count': view_count,
                                    'subscriber_count': subscriber_count,
                                    'upload_date': item['snippet']['publishedAt'],
                                    'description': item['snippet']['description']
                                })
            
            return videos
            
        except Exception as e:
            print(f"âŒ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
            return []
    
    async def extract_subtitle(self, video_id: str) -> Optional[str]:
        """ì˜ìƒ ìë§‰ ì¶”ì¶œ"""
        try:
            # í•œêµ­ì–´ ìë§‰ ìš°ì„  ì‹œë„
            transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)
            
            # ìˆ˜ë™ í•œêµ­ì–´ ìë§‰ ìš°ì„ 
            try:
                transcript = transcript_list.find_manually_created_transcript(['ko'])
            except:
                # ìë™ ìƒì„± í•œêµ­ì–´ ìë§‰
                try:
                    transcript = transcript_list.find_generated_transcript(['ko'])
                except:
                    return None
            
            # ìë§‰ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            subtitle_data = transcript.fetch()
            full_text = ' '.join([item['text'] for item in subtitle_data])
            
            return full_text
            
        except Exception as e:
            print(f"âš ï¸ ìë§‰ ì¶”ì¶œ ì‹¤íŒ¨ ({video_id}): {e}")
            return None
    
    def clean_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ì •ì œ"""
        cleaned = text
        
        # ë¶ˆí•„ìš”í•œ íŒ¨í„´ ì œê±°
        for pattern in self.removal_patterns:
            cleaned = re.sub(pattern, ' ', cleaned, flags=re.IGNORECASE)
        
        # ì—°ì†ëœ ê³µë°± ì œê±°
        cleaned = re.sub(r'\s+', ' ', cleaned)
        
        # ì•ë’¤ ê³µë°± ì œê±°
        cleaned = cleaned.strip()
        
        return cleaned
    
    def extract_structured_data(self, text: str) -> List[Dict]:
        """í…ìŠ¤íŠ¸ë¥¼ êµ¬ì¡°í™”ëœ í•™ìŠµ ë°ì´í„°ë¡œ ë³€í™˜"""
        structured_data = []
        
        # ì‚¬ì£¼ ê´€ë ¨ íŒ¨í„´ ì°¾ê¸°
        patterns = {
            'question_answer': r'(.*?[ëŠ”ì€ì´ê°€]\s+ì–´ë–¤.*?[\?ï¼Ÿ])\s*([^ï¼Ÿ\?]+)',
            'saju_interpretation': r'([ê°‘ì„ë³‘ì •ë¬´ê¸°ê²½ì‹ ì„ê³„][ëª©í™”í† ê¸ˆìˆ˜]\s+ì¼ì£¼[ëŠ”ì€ì´ê°€])\s*([^ã€‚.]+[ã€‚.])',
            'element_description': r'([ëª©í™”í† ê¸ˆìˆ˜]\s+ê¸°ìš´[ì´ê°€])\s*([^ã€‚.]+[ã€‚.])',
            'personality_trait': r'(ì„±ê²©[ì€ì´]|ì„±í–¥[ì€ì´])\s*([^ã€‚.]+[ã€‚.])',
            'fortune_prediction': r'(ìš´ì„¸[ëŠ”ì€ì´ê°€]|ëŒ€ìš´[ì€ì´])\s*([^ã€‚.]+[ã€‚.])'
        }
        
        for pattern_type, pattern in patterns.items():
            matches = re.findall(pattern, text, re.MULTILINE)
            
            for match in matches:
                if len(match) == 2:
                    structured_data.append({
                        'type': pattern_type,
                        'question': match[0].strip(),
                        'answer': match[1].strip(),
                        'confidence_score': self._calculate_confidence(match[1])
                    })
        
        return structured_data
    
    def _calculate_confidence(self, text: str) -> float:
        """í…ìŠ¤íŠ¸ ì‹ ë¢°ë„ ê³„ì‚°"""
        confidence = 0.5  # ê¸°ë³¸ê°’
        
        # ì „ë¬¸ ìš©ì–´ í¬í•¨ ì—¬ë¶€
        saju_terms = ['ì²œê°„', 'ì§€ì§€', 'ì‹­ì‹ ', 'ì˜¤í–‰', 'ì¼ì£¼', 'ëŒ€ìš´', 'ì„¸ìš´']
        for term in saju_terms:
            if term in text:
                confidence += 0.05
        
        # í…ìŠ¤íŠ¸ ê¸¸ì´
        if len(text) > 100:
            confidence += 0.1
        if len(text) > 300:
            confidence += 0.1
        
        # êµ¬ì²´ì ì¸ ì„¤ëª… í¬í•¨
        if any(word in text for word in ['ë”°ë¼ì„œ', 'ê·¸ëŸ¬ë¯€ë¡œ', 'ì™œëƒí•˜ë©´', 'ì˜ˆë¥¼ ë“¤ì–´']):
            confidence += 0.1
        
        return min(confidence, 1.0)
    
    def save_to_database(self, video_data: Dict, subtitle_text: str, structured_data: List[Dict]):
        """ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
        conn = sqlite3.connect('saju_youtube_data.db')
        cursor = conn.cursor()
        
        try:
            # ì˜ìƒ ì •ë³´ ì €ì¥
            cursor.execute("""
                INSERT OR REPLACE INTO crawled_videos 
                (video_id, title, channel_name, channel_id, view_count, 
                 subscriber_count, upload_date, description)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                video_data['video_id'],
                video_data['title'],
                video_data['channel_name'],
                video_data['channel_id'],
                video_data['view_count'],
                video_data['subscriber_count'],
                video_data['upload_date'],
                video_data['description']
            ))
            
            # ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ì €ì¥
            if subtitle_text:
                cleaned_text = self.clean_text(subtitle_text)
                cursor.execute("""
                    INSERT INTO extracted_texts 
                    (video_id, source_type, raw_text, cleaned_text)
                    VALUES (?, ?, ?, ?)
                """, (
                    video_data['video_id'],
                    'subtitle',
                    subtitle_text,
                    cleaned_text
                ))
            
            # êµ¬ì¡°í™”ëœ í•™ìŠµ ë°ì´í„° ì €ì¥
            for data in structured_data:
                cursor.execute("""
                    INSERT INTO structured_learning_data
                    (video_id, question, answer, confidence_score)
                    VALUES (?, ?, ?, ?)
                """, (
                    video_data['video_id'],
                    data.get('question', ''),
                    data.get('answer', ''),
                    data.get('confidence_score', 0.5)
                ))
            
            conn.commit()
            print(f"âœ… ì €ì¥ ì™„ë£Œ: {video_data['title']}")
            
        except Exception as e:
            print(f"âŒ ì €ì¥ ì‹¤íŒ¨: {e}")
            conn.rollback()
        finally:
            conn.close()
    
    async def crawl_all_keywords(self):
        """ëª¨ë“  í‚¤ì›Œë“œë¡œ í¬ë¡¤ë§ ì‹¤í–‰"""
        total_videos = 0
        total_structured_data = 0
        
        for keyword in self.search_keywords:
            print(f"\nğŸ” ê²€ìƒ‰ ì¤‘: {keyword}")
            videos = await self.search_videos(keyword, max_results=20)
            
            for video in videos:
                print(f"  ğŸ“º ì²˜ë¦¬ ì¤‘: {video['title'][:50]}...")
                
                # ìë§‰ ì¶”ì¶œ
                subtitle = await self.extract_subtitle(video['video_id'])
                
                if subtitle:
                    # êµ¬ì¡°í™”ëœ ë°ì´í„° ì¶”ì¶œ
                    structured_data = self.extract_structured_data(subtitle)
                    
                    # ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
                    self.save_to_database(video, subtitle, structured_data)
                    
                    total_videos += 1
                    total_structured_data += len(structured_data)
                
                # API ì œí•œ ë°©ì§€ë¥¼ ìœ„í•œ ì§€ì—°
                await asyncio.sleep(1)
        
        print(f"""
        ========================================
        í¬ë¡¤ë§ ì™„ë£Œ!
        ----------------------------------------
        ì´ ì²˜ë¦¬ëœ ì˜ìƒ: {total_videos}ê°œ
        ì¶”ì¶œëœ í•™ìŠµ ë°ì´í„°: {total_structured_data}ê°œ
        ========================================
        """)
    
    def get_statistics(self):
        """í¬ë¡¤ë§ í†µê³„ í™•ì¸"""
        conn = sqlite3.connect('saju_youtube_data.db')
        cursor = conn.cursor()
        
        cursor.execute("SELECT COUNT(*) FROM crawled_videos")
        video_count = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(*) FROM structured_learning_data")
        data_count = cursor.fetchone()[0]
        
        cursor.execute("SELECT AVG(confidence_score) FROM structured_learning_data")
        avg_confidence = cursor.fetchone()[0] or 0
        
        cursor.execute("""
            SELECT channel_name, COUNT(*) as cnt 
            FROM crawled_videos 
            GROUP BY channel_name 
            ORDER BY cnt DESC 
            LIMIT 5
        """)
        top_channels = cursor.fetchall()
        
        conn.close()
        
        print(f"""
        ğŸ“Š í¬ë¡¤ë§ ë°ì´í„° í†µê³„
        ========================================
        ì´ ì˜ìƒ ìˆ˜: {video_count}ê°œ
        í•™ìŠµ ë°ì´í„°: {data_count}ê°œ
        í‰ê·  ì‹ ë¢°ë„: {avg_confidence:.2f}
        
        ìƒìœ„ ì±„ë„:
        """)
        for channel, count in top_channels:
            print(f"  - {channel}: {count}ê°œ")

async def main():
    # API í‚¤ ì„¤ì • (í™˜ê²½ë³€ìˆ˜ ë˜ëŠ” ì§ì ‘ ì…ë ¥)
    api_key = os.getenv('YOUTUBE_API_KEY')
    if not api_key:
        print("âš ï¸ YOUTUBE_API_KEY í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”")
        print("export YOUTUBE_API_KEY='your-api-key'")
        return
    
    crawler = AdvancedSajuCrawler(api_key)
    
    # ì „ì²´ í¬ë¡¤ë§ ì‹¤í–‰
    await crawler.crawl_all_keywords()
    
    # í†µê³„ í™•ì¸
    crawler.get_statistics()

if __name__ == "__main__":
    asyncio.run(main())